{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import poisson\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "import sasoptpy as so\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "import string\n",
    "import json\n",
    "import subprocess\n",
    "import time\n",
    "import threading\n",
    "from subprocess import Popen\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixture Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal(n):\n",
    "    n = int(n)\n",
    "    if 10 <= n % 100 < 20:\n",
    "        return str(n) + 'th'\n",
    "    else:\n",
    "        return  str(n) + {1 : 'st', 2 : 'nd', 3 : 'rd'}.get(n % 10, \"th\")\n",
    "\n",
    "def generate_fixtures(custom_fixtures = None, exclude_past_games = True, last_date = None, display_ticker=True, display_unformatted=False):\n",
    "    team_data_df = pd.read_csv('../data/team_data.csv')\n",
    "    team_data_dict = team_data_df.set_index('fotmob_team').T.to_dict()\n",
    "    pl_team_list = team_data_dict.keys()\n",
    "\n",
    "    competition_dict = {'pl': {'id': '47', 'ccode3': 'GBR',},\n",
    "                        'fa_cup': {'id': '132', 'ccode3': 'GBR',},\n",
    "                        'league_cup': {'id': '133', 'ccode3': 'GBR',},\n",
    "                        'ucl': {'id': '42', 'ccode3': 'GBR',},\n",
    "                        'europa_league': {'id': '73', 'ccode3': 'GBR',},\n",
    "                        'europa_conference_league': {'id': '10216', 'ccode3': 'GBR',},\n",
    "                        }\n",
    "\n",
    "    fixture_df = pd.DataFrame(columns=('comp', 'home_team', 'away_team', 'short_home_team', 'short_away_team', 'datetime_str', 'date_str', 'datetime_obj'))\n",
    "\n",
    "    fantasy_format = 'TFF'\n",
    "\n",
    "    # need to add other formats and competitions\n",
    "    if fantasy_format == 'FPL':\n",
    "        competition_subset_dict = {k:v for k, v in competition_dict.items() if k == 'pl'}\n",
    "        period_separation = 'fpl_gw'\n",
    "    elif fantasy_format == 'TFF':\n",
    "        competition_subset_dict = {k:v for k, v in competition_dict.items() if k == 'pl'}\n",
    "        period_separation = 'datetime_str'\n",
    "\n",
    "    for key, params in competition_subset_dict.items():\n",
    "        response = requests.get('https://www.fotmob.com/api/leagues', params=params)\n",
    "        data = response.json()\n",
    "        match_dict_list = data['matches']['allMatches']\n",
    "        if key == 'pl':\n",
    "            for match in match_dict_list:\n",
    "                fotmob_home_team = match['home']['shortName']\n",
    "                fotmob_away_team = match['away']['shortName']\n",
    "                datetime_str = match['status']['utcTime']\n",
    "                date_str = match['status']['utcTime'].split(\"T\")[0]\n",
    "                datetime_obj = datetime.datetime.strptime(datetime_str, '%Y-%m-%dT%H:%M:%SZ')\n",
    "                # fpl_gw = match['roundName']\n",
    "\n",
    "                short_home_team = team_data_dict[fotmob_home_team]['short_team']\n",
    "                short_away_team = team_data_dict[fotmob_away_team]['short_team']\n",
    "                fixture_df.loc[len(fixture_df)] = [key, fotmob_home_team, fotmob_away_team, short_home_team, short_away_team, datetime_str, date_str, datetime_obj]\n",
    "    fixture_df['probability'] = 1\n",
    "    fixture_df['is_custom'] = False\n",
    "\n",
    "    # add custom fixtures, an example of the required format is commented out below\n",
    "    # custom_fixtures = pd.DataFrame(columns=('comp', 'home_team', 'away_team', 'datetime_probs'))\n",
    "    # custom_fixtures.loc[len(custom_fixtures)] = ['pl', 'MUN', 'FUL', {'2024-08-16T19:00:00Z':0.5, '2024-08-17T11:30:00Z':0.5}]\n",
    "    # custom_fixtures.loc[len(custom_fixtures)] = ['pl', 'MUN', 'LIV', {'2024-08-16':0.5, '2024-08-17T12:30:00Z':0.5}]\n",
    "    if custom_fixtures is not None:\n",
    "        for index, row in custom_fixtures.iterrows():\n",
    "            comp = row['comp']\n",
    "            short_home_team = row['home_team']\n",
    "            short_away_team = row['away_team']\n",
    "            fixture_df = fixture_df.drop(fixture_df[(fixture_df['comp'] == comp) & (fixture_df['short_home_team'] == short_home_team) & (fixture_df['short_away_team'] == short_away_team)].index).reset_index(drop=True)\n",
    "            for datetime_str, probability in row['datetime_probs'].items():\n",
    "                datetime_obj = parser.parse(datetime_str)\n",
    "                date_str = datetime.datetime.strftime(datetime_obj, \"%Y-%m-%d\")\n",
    "                datetime_str = datetime.datetime.strftime(datetime_obj, '%Y-%m-%dT%H:%M:%SZ')\n",
    "                datetime_obj = datetime.datetime.strptime(datetime_str, '%Y-%m-%dT%H:%M:%SZ')\n",
    "                fotmob_home_team = team_data_df.loc[team_data_df['short_team'] == short_home_team, 'fotmob_team'].values[0]\n",
    "                fotmob_away_team = team_data_df.loc[team_data_df['short_team'] == short_away_team, 'fotmob_team'].values[0]\n",
    "                fixture_df.loc[len(fixture_df)] = [comp, fotmob_home_team, fotmob_away_team, short_home_team, short_away_team, datetime_str, date_str, datetime_obj, probability, True]\n",
    "\n",
    "\n",
    "    fixture_df = fixture_df.sort_values(by='datetime_obj', ascending=True)\n",
    "\n",
    "    # remove matches outside time bounds\n",
    "    if exclude_past_games:\n",
    "        today_datetime = datetime.datetime.today()\n",
    "        for index, row in fixture_df.copy().iterrows():\n",
    "            if row['datetime_str'] < datetime.datetime.strftime(today_datetime, '%Y-%m-%dT%H:%M:%SZ'):\n",
    "                fixture_df = fixture_df.loc[fixture_df['datetime_str']!=row['datetime_str']]\n",
    "        fixture_df.reset_index(drop=True)\n",
    "    if last_date is not None:\n",
    "        last_date_str = datetime.datetime.strftime(parser.parse(last_date) + datetime.timedelta(days=1), \"%Y-%m-%d\")\n",
    "        for index, row in fixture_df.copy().iterrows():\n",
    "            if row['datetime_str'] > last_date_str:\n",
    "                fixture_df = fixture_df.loc[fixture_df['datetime_str']!=row['datetime_str']]\n",
    "        fixture_df.reset_index(drop=True)\n",
    "\n",
    "    gw_ref = pd.read_csv('../data/gw_ref.csv')\n",
    "    fixture_df = pd.merge(left=fixture_df, right=gw_ref, on='date_str')\n",
    "\n",
    "    num_unique_datetime = len(fixture_df[period_separation].unique())\n",
    "    fixture_ticker = pd.DataFrame(columns=['team'] + ['short_team'] +list(fixture_df[period_separation].unique()))\n",
    "\n",
    "    for team in pl_team_list:\n",
    "        fixture_ticker.loc[len(fixture_ticker)] = [team] + [team_data_df.loc[team_data_df['fotmob_team']==team,'short_team'].values[0]] + [''] * num_unique_datetime\n",
    "\n",
    "    for index, row in fixture_df.iterrows():\n",
    "        prob_str = ''\n",
    "        if row['probability'] != 1:\n",
    "            prob_str = '*' + str(round(row['probability'],2))[1:]\n",
    "        if row['home_team'] in pl_team_list:\n",
    "            fixture_ticker.loc[fixture_ticker['team'] == row['home_team'], [row[period_separation]]] += '\\n'+row['short_away_team'] + prob_str\n",
    "        if row['away_team'] in pl_team_list:\n",
    "            fixture_ticker.loc[fixture_ticker['team'] == row['away_team'], [row[period_separation]]] += '\\n'+row['short_home_team'].lower() + prob_str\n",
    "\n",
    "    # make formatted dataframe\n",
    "    f_fixture_ticker = fixture_ticker.copy()\n",
    "    datetime_str_cols = [x for i, x in enumerate(f_fixture_ticker.columns.tolist()) if len(x)>10]\n",
    "    numeric_header =  [str(i-1) if 'team' not in x else x for i, x in enumerate(f_fixture_ticker.columns.tolist())]\n",
    "    time_header = ['',''] + [parser.parse(x).strftime(\"%H:%M\") for x in datetime_str_cols]\n",
    "    daynum_header = ['',''] + [ordinal(parser.parse(x).strftime(\"%d\")) for x in datetime_str_cols]\n",
    "    weekday_header = ['',''] + [parser.parse(x).strftime(\"%a\") for x in datetime_str_cols]\n",
    "    gw_ref = pd.read_csv('../data/gw_ref.csv')\n",
    "    tff_gw_header = ['',''] + ['GW' + str(gw_ref.loc[gw_ref['date_str']== x.split('T')[0], 'tff_gw'].values[0]) for x in datetime_str_cols]\n",
    "    month_header = ['',''] + [parser.parse(x).strftime(\"%b\") for x in datetime_str_cols]\n",
    "    f_fixture_ticker.columns = [month_header, tff_gw_header, weekday_header, daynum_header, time_header, numeric_header]\n",
    "    # Make color map dictionary and function\n",
    "    team_data_df['h_gd'] = team_data_df['g_for']*team_data_df['home_adv'] - team_data_df['g_against']/team_data_df['home_adv']\n",
    "    team_data_df['a_gd'] = team_data_df['g_for']/team_data_df['home_adv'] - team_data_df['g_against']*team_data_df['home_adv']\n",
    "    color_ts = team_data_df[['short_team','h_gd', 'a_gd']].copy()\n",
    "    min_gd = min(color_ts['h_gd'].values.tolist() + color_ts['a_gd'].values.tolist())*2.3\n",
    "    max_gd = max(color_ts['h_gd'].values.tolist() + color_ts['a_gd'].values.tolist())#*1.8\n",
    "    norm = matplotlib.colors.Normalize(vmin=min_gd, vmax=max_gd, clip=True)\n",
    "    mapper = plt.cm.ScalarMappable(norm=norm, cmap=plt.cm.viridis_r)\n",
    "    color_ts['h_gd_color'] = color_ts['h_gd'].apply(lambda x: mcolors.to_hex(mapper.to_rgba(x)))\n",
    "    color_ts['a_gd_color'] = color_ts['a_gd'].apply(lambda x: mcolors.to_hex(mapper.to_rgba(x)))\n",
    "    h_teams = color_ts['short_team'].values.tolist()\n",
    "    a_teams = [team.lower() for team in h_teams]\n",
    "    teams = h_teams + a_teams\n",
    "    team_gd = color_ts['a_gd_color'].values.tolist() + color_ts['h_gd_color'].values.tolist()\n",
    "    color_dict = {teams[i]: team_gd[i] for i in range(len(teams))}\n",
    "    def color_col(col, pattern_map, default=''):\n",
    "        return np.select(\n",
    "            [col.str.contains(k, na=False) for k in pattern_map.keys()],\n",
    "            [f'background-color: {v}' for v in pattern_map.values()],\n",
    "            default=default\n",
    "        ).astype(str)\n",
    "    # Apply styles\n",
    "    f_fixture_ticker = f_fixture_ticker.style.apply(color_col,\n",
    "                                                pattern_map=color_dict\n",
    "                                                , subset=f_fixture_ticker.columns[2:]\n",
    "                                                )\n",
    "    f_fixture_ticker = f_fixture_ticker.set_table_styles([\n",
    "                        {'selector': 'th.col_heading', 'props': 'text-align: left;'},\n",
    "                        {'selector': 'th.col_heading.level0', 'props': 'font-size: 1em;'},\n",
    "                        {'selector': 'td', 'props': 'text-align: center; font-weight: bold;'},\n",
    "                    ], overwrite=False)\n",
    "    f_fixture_ticker = f_fixture_ticker.set_properties(**{'color': 'white'},subset=(f_fixture_ticker.columns[2:]))\n",
    "\n",
    "    if display_ticker:\n",
    "        if display_unformatted:\n",
    "            fixture_ticker = fixture_ticker.replace('\\n',' ', regex=True)\n",
    "            fixture_ticker.columns = [month_header, tff_gw_header, weekday_header, daynum_header, time_header, numeric_header]\n",
    "            display(fixture_ticker)\n",
    "        else:\n",
    "            display(f_fixture_ticker)\n",
    "\n",
    "    return {'f_fixture_ticker': f_fixture_ticker, 'unf_fixture_ticker': fixture_ticker, 'fixture_df': fixture_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_data_gen(fixture_df):\n",
    "    player_data = pd.read_csv('../data/player_data.csv')\n",
    "\n",
    "    all_gw_list = sorted(fixture_df['fpl_gw'].unique())\n",
    "    \n",
    "    try:\n",
    "        filepath = '../data/fplreview.csv'\n",
    "        fplreview = pd.read_csv(filepath)\n",
    "        fplreview = fplreview.rename(columns={'ID': 'fpl_id'})\n",
    "        review_xmins = True\n",
    "        print(f\"Using minutes from {filepath}\")\n",
    "    except:\n",
    "        review_xmins = False\n",
    "        print(f\"{filepath} not found, using default baseline minutes\") \n",
    "\n",
    "    if review_xmins:\n",
    "        review_gw_list = []\n",
    "        for element in list(fplreview.columns.values):\n",
    "            if '_xMins' in element:\n",
    "                review_gw_list.append(int(element.split('_')[0]))\n",
    "        review_gw_list.sort()\n",
    "        for gw in all_gw_list:\n",
    "            if gw < review_gw_list[0]:\n",
    "                fplreview[f'{gw}_xMins'] = fplreview[f'{review_gw_list[0]}_xMins']\n",
    "            elif gw > review_gw_list[-1]:\n",
    "                fplreview[f'{gw}_xMins'] = fplreview[f'{review_gw_list[-1]}_xMins']\n",
    "        player_data = pd.merge(player_data, fplreview.loc[:,['fpl_id'] + [f'{x}_xMins' for x in all_gw_list]], on=['fpl_id'], how='inner')\n",
    "\n",
    "    else:\n",
    "        for gw in all_gw_list:\n",
    "            player_data[str(gw)+'_xMins'] = player_data['bl_xmin']\n",
    "    return player_data\n",
    "\n",
    "\n",
    "def eg_to_cs(eg=1.61):\n",
    "    return poisson.cdf(k=0, mu=eg)\n",
    "\n",
    "\n",
    "def pen_takers_from_fix(player_data, short_team = 'NEW', fpl_gw = 1, n_pens = 0.2):\n",
    "    player_data_subset = player_data.loc[(player_data['short_team']==short_team) & (player_data['on_pens']>0) & (player_data[f'{fpl_gw}_xMins']>0)]\n",
    "    pen_taker_dict = {player_row['tff_id']: (player_row[f'{fpl_gw}_xMins']**2.5)*(player_row['on_pens']**0.8)/95 for player_index, player_row in player_data_subset.iterrows()}\n",
    "    value_sum = sum(pen_taker_dict.values())\n",
    "    pen_taker_dict = {key: round(value*n_pens/value_sum, 3) for key, value in pen_taker_dict.items()}\n",
    "    return pen_taker_dict\n",
    "\n",
    "def np_scorers_from_fix(player_data, short_team = 'NEW', fpl_gw = 1, team_npg = 1.5):\n",
    "    player_data_subset = player_data.loc[(player_data['short_team']==short_team) & (player_data['bl_npxg']>0.01) & (player_data[f'{fpl_gw}_xMins']>0)]\n",
    "    npg_dict = {player_row['tff_id']: player_row[f'{fpl_gw}_xMins']*player_row['bl_npxg']*player_row['fin_skill']/95 for player_index, player_row in player_data_subset.iterrows()}\n",
    "    npg_sum = sum(npg_dict.values())\n",
    "    npg_dict = {key: round(value*team_npg/npg_sum, 3) for key, value in npg_dict.items()}\n",
    "    return npg_dict\n",
    "\n",
    "def assisters_from_fix(player_data, short_team = 'NEW', fpl_gw = 1, team_ag = 1.5):\n",
    "    player_data_subset = player_data.loc[(player_data['short_team']==short_team) & (player_data['bl_a']>0.01) & (player_data[f'{fpl_gw}_xMins']>0)]\n",
    "    a_dict = {player_row['tff_id']: player_row[f'{fpl_gw}_xMins']*player_row['bl_a']/95 for player_index, player_row in player_data_subset.iterrows()}\n",
    "    a_sum = sum(a_dict.values())\n",
    "    a_dict = {key: round(value*team_ag/a_sum, 3) for key, value in a_dict.items()}\n",
    "    return a_dict\n",
    "\n",
    "def list_players_in_team(player_data, short_team = 'NEW', fpl_gw = 1, xmin_cutoff=10):\n",
    "    player_data_subset = player_data.loc[(player_data['short_team']==short_team) & (player_data[f'{fpl_gw}_xMins']>xmin_cutoff)]\n",
    "    player_list = player_data_subset['tff_id'].to_list()\n",
    "    return player_list\n",
    "\n",
    "def read_probability_data(player_data, team_data_df, append_filename = ''):\n",
    "\n",
    "    probability_dfs = pd.read_excel(f'../data/probability_data_raw{append_filename}.xlsx', sheet_name=None)\n",
    "    probability_dfs['Assist'] = probability_dfs['Assist'].rename(columns={'eGoals/90': 'eAssists/90', 'Anytime Goal %': 'Anytime Assist %'})\n",
    "\n",
    "    probability_dfs['Scorer'] = pd.merge(left=probability_dfs['Scorer'], right=player_data.loc[:,['fpl_id', 'tff_id']], left_on='ID', right_on='fpl_id')\n",
    "    probability_dfs['Assist'] = pd.merge(left=probability_dfs['Assist'], right=player_data.loc[:,['fpl_id', 'tff_id']], left_on='ID', right_on='fpl_id')\n",
    "\n",
    "    shortname_replace_dict = {row['review_short_team']: row['short_team'] for index, row in team_data_df.iterrows()}\n",
    "    for key, df in probability_dfs.items():\n",
    "        probability_dfs[key] = df.replace(shortname_replace_dict, regex=True)\n",
    "\n",
    "    return probability_dfs\n",
    "\n",
    "def add_aux_player_data(player_data, prob_dfs, own_team, opp_team, home_or_away='H', external_data_gws=[], gw=1, stat='Goals'):\n",
    "    if gw not in external_data_gws or prob_dfs is None:\n",
    "        return {}\n",
    "    else:\n",
    "        prob_df_dict = {'Goals':'Scorer', 'Assists':'Assist'}\n",
    "        aux_df = prob_dfs[prob_df_dict[stat]]\n",
    "        aux_df_subset = aux_df.loc[(aux_df['Team']==own_team) & (aux_df['Fixture']==f'({home_or_away}): {opp_team}') & (aux_df['GW']==gw)]\n",
    "        return {row['tff_id']: row[f'e{stat}/90']*player_data.loc[player_data['tff_id']==row['tff_id'], f'{gw}_xMins'].values[0]/95 for index, row in aux_df_subset.iterrows()}\n",
    "\n",
    "def add_team_lvl_projections(player_data, fixture_df, xmin_cutoff=10, aux_weight=0.8):\n",
    "\n",
    "    team_data_df = pd.read_csv('../data/team_data.csv')\n",
    "    if aux_weight > 0:\n",
    "        try:\n",
    "            prob_dfs = read_probability_data(player_data=player_data, team_data_df=team_data_df)\n",
    "            external_data_gws = list(prob_dfs['CS']['GW'])\n",
    "            print(f\"Using external probability data with weight: {aux_weight}\")\n",
    "        except:\n",
    "            external_data_gws = []\n",
    "            prob_dfs = None\n",
    "    else:\n",
    "        external_data_gws = []\n",
    "        prob_dfs = None\n",
    "\n",
    "    fixture_df['home_g'] = 1.1\n",
    "    fixture_df['home_cs'] = 0.5\n",
    "    fixture_df['away_g'] = 1.1\n",
    "    fixture_df['away_cs'] = 0.5\n",
    "\n",
    "    fixture_df['home_pen_takers'] = pd.Series(dtype='object')\n",
    "    fixture_df['away_pen_takers'] = pd.Series(dtype='object')\n",
    "\n",
    "    fixture_df['home_np_scorers'] = pd.Series(dtype='object')\n",
    "    fixture_df['away_np_scorers'] = pd.Series(dtype='object')\n",
    "\n",
    "    fixture_df['home_assisters'] = pd.Series(dtype='object')\n",
    "    fixture_df['away_assisters'] = pd.Series(dtype='object')\n",
    "\n",
    "    fixture_df['home_players'] = pd.Series(dtype='object')\n",
    "    fixture_df['away_players'] = pd.Series(dtype='object')\n",
    "\n",
    "    fixture_df['home_aux_goals'] = pd.Series(dtype='object')\n",
    "    fixture_df['away_aux_goals'] = pd.Series(dtype='object')\n",
    "    fixture_df['home_aux_assists'] = pd.Series(dtype='object')\n",
    "    fixture_df['away_aux_assists'] = pd.Series(dtype='object')\n",
    "\n",
    "    for match_index, match_row in fixture_df.iterrows():\n",
    "        home_g = team_data_df.loc[team_data_df['short_team'] == match_row['short_home_team'], 'g_for'].values[0] * team_data_df.loc[team_data_df['short_team'] == match_row['short_home_team'], 'home_adv'].values[0] * team_data_df.loc[team_data_df['short_team'] == match_row['short_away_team'], 'g_against_k'].values[0]\n",
    "        away_g = team_data_df.loc[team_data_df['short_team'] == match_row['short_away_team'], 'g_for'].values[0] / team_data_df.loc[team_data_df['short_team'] == match_row['short_away_team'], 'home_adv'].values[0] * team_data_df.loc[team_data_df['short_team'] == match_row['short_home_team'], 'g_against_k'].values[0]\n",
    "        fixture_df.at[match_index, 'away_g'] = away_g\n",
    "        fixture_df.at[match_index, 'home_g'] = home_g\n",
    "\n",
    "        if match_row['comp']=='pl' and match_row['fpl_gw'] in external_data_gws and not match_row['is_custom']:\n",
    "            fixture_df.at[match_index, 'home_cs'] = eg_to_cs(away_g) * (1-aux_weight) + prob_dfs['CS'].loc[(prob_dfs['CS']['Team_Abbr']==match_row['short_home_team']) & (prob_dfs['CS']['Opp']==match_row['short_away_team']) & (prob_dfs['CS']['GW']==match_row['fpl_gw']), 'CS%'].values[0] * aux_weight\n",
    "            fixture_df.at[match_index, 'away_cs'] = eg_to_cs(home_g) * (1-aux_weight) + prob_dfs['CS'].loc[(prob_dfs['CS']['Team_Abbr']==match_row['short_away_team']) & (prob_dfs['CS']['Opp']==match_row['short_home_team']) & (prob_dfs['CS']['GW']==match_row['fpl_gw']), 'CS%'].values[0] * aux_weight\n",
    "        else:\n",
    "            fixture_df.at[match_index, 'home_cs'] = eg_to_cs(away_g)\n",
    "            fixture_df.at[match_index, 'away_cs'] = eg_to_cs(home_g)\n",
    "\n",
    "        n_home_pens = team_data_df.loc[team_data_df['short_team'] == match_row['short_home_team'], 'pk_att_for'].values[0] * team_data_df.loc[team_data_df['short_team'] == match_row['short_home_team'], 'home_adv'].values[0] * team_data_df.loc[team_data_df['short_team'] == match_row['short_away_team'], 'pk_att_against_k'].values[0]\n",
    "        n_away_pens = team_data_df.loc[team_data_df['short_team'] == match_row['short_away_team'], 'pk_att_for'].values[0] / team_data_df.loc[team_data_df['short_team'] == match_row['short_away_team'], 'home_adv'].values[0] * team_data_df.loc[team_data_df['short_team'] == match_row['short_home_team'], 'pk_att_against_k'].values[0]\n",
    "\n",
    "        h_p_dict = pen_takers_from_fix(short_team = match_row['short_home_team'], fpl_gw = match_row['fpl_gw'], player_data = player_data, n_pens = n_home_pens) \n",
    "        fixture_df.at[match_index, 'home_pen_takers'] = h_p_dict\n",
    "        a_p_dict = pen_takers_from_fix(short_team = match_row['short_away_team'], fpl_gw = match_row['fpl_gw'], player_data = player_data, n_pens = n_away_pens)\n",
    "        fixture_df.at[match_index, 'away_pen_takers'] = a_p_dict\n",
    "\n",
    "        # team goals adjusted for penalties, and the number of own goals per goal\n",
    "        h_npg_dict = np_scorers_from_fix(short_team = match_row['short_home_team'], fpl_gw = match_row['fpl_gw'], player_data = player_data, team_npg = (home_g-(n_home_pens*0.79))*0.965)\n",
    "        fixture_df.at[match_index, 'home_np_scorers'] = h_npg_dict\n",
    "        a_npg_dict = np_scorers_from_fix(short_team = match_row['short_away_team'], fpl_gw = match_row['fpl_gw'], player_data = player_data, team_npg = (away_g-(n_away_pens*0.79))*0.965)\n",
    "        fixture_df.at[match_index, 'away_np_scorers'] = a_npg_dict\n",
    "\n",
    "        # team goals adjusted for number of assists per goal in telegraph in 23/24 (0.90045...)\n",
    "        fixture_df.at[match_index, 'home_assisters'] = assisters_from_fix(short_team = match_row['short_home_team'], fpl_gw = match_row['fpl_gw'], player_data = player_data, team_ag = home_g*0.9005)\n",
    "        fixture_df.at[match_index, 'away_assisters'] = assisters_from_fix(short_team = match_row['short_away_team'], fpl_gw = match_row['fpl_gw'], player_data = player_data, team_ag = away_g*0.9005)\n",
    "        \n",
    "        fixture_df.at[match_index, 'home_players'] = list_players_in_team(short_team = match_row['short_home_team'], fpl_gw = match_row['fpl_gw'], player_data = player_data, xmin_cutoff = xmin_cutoff)\n",
    "        fixture_df.at[match_index, 'away_players'] = list_players_in_team(short_team = match_row['short_away_team'], fpl_gw = match_row['fpl_gw'], player_data = player_data, xmin_cutoff = xmin_cutoff)\n",
    "\n",
    "        fixture_df.at[match_index,'home_aux_goals'] = add_aux_player_data(player_data=player_data, prob_dfs=prob_dfs, own_team=match_row['short_home_team'], opp_team=match_row['short_away_team'], home_or_away='H', external_data_gws=external_data_gws, gw=match_row['fpl_gw'], stat='Goals')\n",
    "        fixture_df.at[match_index,'away_aux_goals'] = add_aux_player_data(player_data=player_data, prob_dfs=prob_dfs, own_team=match_row['short_away_team'], opp_team=match_row['short_home_team'], home_or_away='A', external_data_gws=external_data_gws, gw=match_row['fpl_gw'], stat='Goals')\n",
    "        fixture_df.at[match_index,'home_aux_assists'] = add_aux_player_data(player_data=player_data, prob_dfs=prob_dfs, own_team=match_row['short_home_team'], opp_team=match_row['short_away_team'], home_or_away='H', external_data_gws=external_data_gws, gw=match_row['fpl_gw'], stat='Assists')\n",
    "        fixture_df.at[match_index,'away_aux_assists'] = add_aux_player_data(player_data=player_data, prob_dfs=prob_dfs, own_team=match_row['short_away_team'], opp_team=match_row['short_home_team'], home_or_away='A', external_data_gws=external_data_gws, gw=match_row['fpl_gw'], stat='Assists')\n",
    "\n",
    "    fixture_df = fixture_df.round(2)\n",
    "\n",
    "    return fixture_df\n",
    "\n",
    "def tff_ev_calc(player_dict, opp_dict, team_dict, fpl_gw=1, e_npg=0.3, e_pen=0.01, e_assists=0.3, cs=0.2, ga=1.5, aux_goal_dict={}, aux_assist_dict={}, aux_weight=0.8):\n",
    "\n",
    "    xmin = player_dict[f'{fpl_gw}_xMins']\n",
    "    x_95s = xmin/95\n",
    "    p_start = (0.5)*(0.5 + np.cbrt((x_95s-0.5)/4)) + (0.5)*x_95s\n",
    "    p_sub = (1-p_start) * x_95s\n",
    "\n",
    "    ev = 0\n",
    "    ev += 2 * p_start\n",
    "    ev += 1 * p_sub\n",
    "\n",
    "    e_goals = e_npg + e_pen*player_dict['fin_skill']*0.79\n",
    "    ev += 5 * (e_goals*(1-aux_weight) + aux_goal_dict.get(player_dict['tff_id'], e_goals)*aux_weight)\n",
    "\n",
    "    ev -= 2 * e_pen / player_dict['fin_skill'] * 0.21\n",
    "    ev += 3 * (e_assists*(1-aux_weight) + aux_assist_dict.get(player_dict['tff_id'], e_assists)*aux_weight)\n",
    "\n",
    "    if player_dict['tff_position'] < 2.5:\n",
    "        ev += 5 * cs * p_start * player_dict['bl_p_60_given_start']\n",
    "        ev += 2 * cs * (p_start*(1-player_dict['bl_p_60_given_start']) + p_sub)\n",
    "        # approximation of poisson cdf sum, coeffs: array([-0.01146325,  0.0888773 ,  0.34962138, -0.06239911,  0.0041391 ])\n",
    "        mu_gc = ga * x_95s\n",
    "        ev -= max((0.0041391*(mu_gc**4) - 0.06239911*(mu_gc**3) + 0.34962138*(mu_gc**2) + 0.0888773*mu_gc - 0.01146325), 0)\n",
    "        if player_dict['tff_position'] == 1:\n",
    "            # approximation of poisson cdf sum, coeffs: array([-0.05142347,  0.28689925,  0.07500592, -0.01004676,  0.00034356])\n",
    "            mu_sv = player_dict['bl_sv_per_sot'] * opp_dict['sot_for'] * team_dict['sot_against_k'] * x_95s\n",
    "            ev += max(0.00034356*(mu_sv**4) - 0.01004676*(mu_sv**3) + 0.07500592*(mu_sv**2) + 0.28689925*mu_sv - 0.05142347, 0)\n",
    "            ev += 5 * opp_dict['pk_att_for'] * team_dict['pk_att_against_k'] * 0.11 * x_95s\n",
    "\n",
    "    if player_dict['tff_position'] == 3:\n",
    "        # approximation of poisson cdf sum, fbref tackles won adjusted for telegraph\n",
    "        mu_tackle = player_dict['bl_tackle'] * opp_dict['tackle_against_k'] * x_95s * 1.7\n",
    "        ev += (1-poisson.cdf(k=1, mu=mu_tackle)) + (1-poisson.cdf(k=3, mu=mu_tackle)) + (1-poisson.cdf(k=5, mu=mu_tackle)) + (1-poisson.cdf(k=7, mu=mu_tackle)) \\\n",
    "            + (1-poisson.cdf(k=9, mu=mu_tackle)) + (1-poisson.cdf(k=11, mu=mu_tackle)) + (1-poisson.cdf(k=13, mu=mu_tackle)) + (1-poisson.cdf(k=15, mu=mu_tackle)) \n",
    "        # ev += max(0.00034356*(mu_tackle**4) - 0.01004676*(mu_tackle**3) + 0.07500592*(mu_tackle**2) + 0.28689925*mu_tackle - 0.05142347, 0)\n",
    "\n",
    "    ev -= 1 * player_dict['bl_yc'] * opp_dict['yc_against_k'] * x_95s\n",
    "    ev -= 3 * player_dict['bl_rc'] * opp_dict['rc_against_k'] * x_95s\n",
    "    ev -= 3 * player_dict['bl_og'] * opp_dict['og_against_k'] * x_95s\n",
    "\n",
    "    return ev\n",
    "\n",
    "def generate_ev(custom_fixtures=None, exclude_past_games=True, last_date=None, xmin_cutoff=0, display_model_output=True, aux_weight=0.8):\n",
    "\n",
    "    fixture_results_r = generate_fixtures(custom_fixtures=custom_fixtures, exclude_past_games=exclude_past_games, last_date=last_date, display_ticker=False)\n",
    "\n",
    "    player_data = player_data_gen(fixture_df = fixture_results_r['fixture_df'])\n",
    "    team_data = pd.read_csv('../data/team_data.csv')\n",
    "\n",
    "\n",
    "    print('Adding team level projections')\n",
    "    fixture_df = add_team_lvl_projections(player_data = player_data, fixture_df = fixture_results_r['fixture_df'], xmin_cutoff=xmin_cutoff, aux_weight=aux_weight)\n",
    "\n",
    "    fixture_times = list(fixture_df['datetime_str'].unique())\n",
    "\n",
    "    # initialize player ev dataframe\n",
    "    pos_dict = {1: 'G', 2: 'D', 3: 'M', 4: 'F'}\n",
    "    columns = ['tff_id', 'team', 'player', 'tff_pos', 'tff_cost'] + fixture_times + ['total_pts', 'ppm']\n",
    "    ev_df = pd.DataFrame(columns = columns)\n",
    "    for index, row in player_data.iterrows():\n",
    "        ev_df.loc[len(ev_df)] = [int(row['tff_id']), row['short_team'], row['fpl_web_player'], pos_dict[row['tff_position']], row['tff_cost']] + [0] * (len(fixture_times)+2)\n",
    "\n",
    "    print('Caculating player EV')\n",
    "    # populate ev dataframe\n",
    "    for match_index, match_row in fixture_df.iterrows():\n",
    "        fix_prob = match_row['probability']\n",
    "        datetime_str = match_row['datetime_str']\n",
    "        fpl_gw = match_row['fpl_gw']\n",
    "        for player_id in match_row['home_players']:\n",
    "            player_dict = player_data.loc[player_data['tff_id']==player_id].to_dict('records')[0]\n",
    "            team_dict = team_data.loc[team_data['short_team']==match_row['short_home_team']].to_dict('records')[0]\n",
    "            opp_dict = team_data.loc[team_data['short_team']==match_row['short_away_team']].to_dict('records')[0]\n",
    "            e_npg = match_row['home_np_scorers'].get(player_id, 0)\n",
    "            e_pen = match_row['home_pen_takers'].get(player_id, 0)\n",
    "            e_assists = match_row['home_assisters'].get(player_id, 0)\n",
    "            cs = match_row['home_cs']\n",
    "            ga = match_row['away_g']\n",
    "            aux_goal_dict = match_row['home_aux_goals']\n",
    "            aux_assist_dict = match_row['home_aux_assists']\n",
    "            ev = tff_ev_calc(player_dict=player_dict, opp_dict=opp_dict, team_dict=team_dict, fpl_gw=fpl_gw, e_npg=e_npg, e_pen=e_pen, e_assists=e_assists, cs=cs, ga=ga, aux_goal_dict=aux_goal_dict, aux_assist_dict=aux_assist_dict, aux_weight=aux_weight)\n",
    "            ev_df.loc[ev_df['tff_id'] == player_id, datetime_str] += ev * fix_prob\n",
    "        for player_id in match_row['away_players']:\n",
    "            player_dict = player_data.loc[player_data['tff_id']==player_id].to_dict('records')[0]\n",
    "            team_dict = team_data.loc[team_data['short_team']==match_row['short_away_team']].to_dict('records')[0]\n",
    "            opp_dict = team_data.loc[team_data['short_team']==match_row['short_home_team']].to_dict('records')[0]\n",
    "            e_npg = match_row['away_np_scorers'].get(player_id, 0)\n",
    "            e_pen = match_row['away_pen_takers'].get(player_id, 0)\n",
    "            e_assists = match_row['away_assisters'].get(player_id, 0)\n",
    "            cs = match_row['away_cs']\n",
    "            ga = match_row['home_g']\n",
    "            aux_goal_dict = match_row['away_aux_goals']\n",
    "            aux_assist_dict = match_row['away_aux_assists']\n",
    "            ev = tff_ev_calc(player_dict=player_dict, opp_dict=opp_dict, team_dict=team_dict, fpl_gw=fpl_gw, e_npg=e_npg, e_pen=e_pen, e_assists=e_assists, cs=cs, ga=ga, aux_goal_dict=aux_goal_dict, aux_assist_dict=aux_assist_dict, aux_weight=aux_weight)\n",
    "            ev_df.loc[ev_df['tff_id'] == player_id, datetime_str] += ev * fix_prob\n",
    "\n",
    "    ev_df['total_pts'] = ev_df.loc[:, fixture_times].sum(axis=1)\n",
    "    ev_df['ppm'] = ev_df['total_pts'] / ev_df['tff_cost']\n",
    "    ev_df = ev_df.sort_values(by='total_pts', ascending=False).reset_index(drop=True)\n",
    "    for column in ev_df.columns:\n",
    "        if column in fixture_times:\n",
    "            ev_df[column] = ev_df[column].astype('float64')\n",
    "    ev_df = ev_df.round(2)\n",
    "\n",
    "    filepath = '../data/tff_model_output.csv'\n",
    "    ev_df.to_csv(filepath, index=False)\n",
    "    print(f'Player EV dataframe saved to {filepath}')\n",
    "    if display_model_output:\n",
    "        display(ev_df.head())\n",
    "\n",
    "    return {'ev_df':ev_df, 'fixture_df':fixture_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'tff_pos': ['G', 'D', 'M', 'F'],\n",
    "        'squad_min_play': [1, 3, 3, 1],\n",
    "        'squad_max_play': [1, 5 ,5, 3]}\n",
    "type_data = pd.DataFrame(data, index=[1,2,3,4])\n",
    "\n",
    "def preprocess_dfs(ev_df, fixture_df, initial_squad=None, last_date=None, flatten_dates_after=None, \n",
    "                   total_pts_cutoff=None, ppm_cutoff=None, weekly_decay=None):\n",
    "\n",
    "    fixture_map = fixture_df.copy()\n",
    "    fixture_map = fixture_map.loc[:, ['datetime_str', 'date_str', 'datetime_obj', 'fpl_gw', 'tff_gw']]\n",
    "    fixture_map = fixture_map.drop_duplicates(subset='datetime_str', keep=\"last\").reset_index(drop=True)\n",
    "\n",
    "    # remove matches after last date\n",
    "    if last_date is not None:\n",
    "        dropped_datetime_strs = []\n",
    "        last_date_str = datetime.datetime.strftime(parser.parse(last_date) + datetime.timedelta(days=1), \"%Y-%m-%d\")\n",
    "        for index, row in fixture_map.copy().iterrows():\n",
    "            if row['datetime_str'] > last_date_str:\n",
    "                dropped_datetime_strs += [row['datetime_str']]\n",
    "                fixture_map = fixture_map.loc[fixture_map['datetime_str']!=row['datetime_str']]\n",
    "        fixture_map.reset_index(drop=True)\n",
    "        ev_df = ev_df.drop(dropped_datetime_strs, axis=1)\n",
    "    \n",
    "    # add matchtime labels\n",
    "    fixture_map['matchtime'] = 1\n",
    "    matchtime_counter = 1\n",
    "    for index, row in fixture_map.copy().iterrows():\n",
    "        fixture_map.loc[index, 'matchtime'] = matchtime_counter\n",
    "        matchtime_counter += 1\n",
    "\n",
    "    # add decay column\n",
    "    if weekly_decay is not None:\n",
    "        first_date_str = list(fixture_map['date_str'])[0]\n",
    "        daily_decay = weekly_decay ** (1/7)\n",
    "        fixture_map['decay'] = 1\n",
    "        for index, row in fixture_map.copy().iterrows():\n",
    "            fixture_map.loc[index, 'decay'] = daily_decay**(parser.parse(row['date_str'])-parser.parse(first_date_str)).days\n",
    "\n",
    "    # sum ev columns after flatten_dates_after into one column\n",
    "    if flatten_dates_after is not None:\n",
    "        flatten_date_str = datetime.datetime.strftime(parser.parse(flatten_dates_after) + datetime.timedelta(days=1), \"%Y-%m-%d\")\n",
    "        removed_datetime_decays = {}\n",
    "        for index, row in fixture_map.copy().iterrows():\n",
    "            if row['datetime_str'] > flatten_date_str:\n",
    "                fixture_map = fixture_map.loc[fixture_map['datetime_str']!=row['datetime_str']]\n",
    "                removed_datetime_decays[row['datetime_str']] = row['decay']\n",
    "        last_remaining_date_str = fixture_map.tail(1).loc[:,'datetime_str'].values[0]\n",
    "        last_remaining_decay = fixture_map.tail(1).loc[:,'decay'].values[0]\n",
    "        for removed_datetime_str, decay in removed_datetime_decays.items():\n",
    "            ev_df[last_remaining_date_str] += ev_df[removed_datetime_str] * decay / last_remaining_decay\n",
    "            ev_df = ev_df.drop(removed_datetime_str, axis=1)\n",
    "        ev_df[last_remaining_date_str] = round(ev_df[last_remaining_date_str], 2)\n",
    "\n",
    "    # remove players outside of pts and ppm cutoffs\n",
    "    if initial_squad is None:\n",
    "        initial_squad = []\n",
    "    if total_pts_cutoff is not None:\n",
    "        total_pts_cutoff = total_pts_cutoff * ev_df['total_pts'].max()\n",
    "        ev_df = ev_df.loc[(ev_df['total_pts']>total_pts_cutoff) | (ev_df['tff_id'].isin(initial_squad))]\n",
    "    if ppm_cutoff is not None:\n",
    "        ppm_cutoff = ppm_cutoff * ev_df['ppm'].max()\n",
    "        ev_df = ev_df.loc[(ev_df['ppm']>ppm_cutoff) | (ev_df['tff_id'].isin(initial_squad))]\n",
    "\n",
    "    ev_df = ev_df.rename(columns={row['datetime_str']: f\"{row['matchtime']}_pts\" for index, row in fixture_map.iterrows()})\n",
    "\n",
    "    fixture_map = fixture_map.set_index('matchtime')\n",
    "    ev_df = ev_df.set_index('tff_id')\n",
    "    \n",
    "    return {'ev_df': ev_df, 'fixture_map': fixture_map}\n",
    "\n",
    "def get_random_id(n):\n",
    "    return ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(n))\n",
    "\n",
    "def read_squad_from_json(squad_name):\n",
    "    with open('../data/tff_squads.json', 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "    return data[squad_name]\n",
    "\n",
    "def check_squad_and_save(squad=[], save_team_as=None):\n",
    "\n",
    "    if squad==[] and save_team_as is not None:\n",
    "        print('No players in team to save')\n",
    "        return\n",
    "\n",
    "    squad_info = ''\n",
    "    invalidity_message = ''\n",
    "    player_data = pd.read_csv('../data/player_data.csv')\n",
    "    player_data['tff_id'] = player_data['tff_id'].astype(int)\n",
    "    \n",
    "    seen = set()\n",
    "    dupes = [str(x) for x in squad if x in seen or seen.add(x)]\n",
    "    if dupes != []:\n",
    "        # display(dupes)\n",
    "        invalidity_message += '\\nDuplicates found in team: ' + ', '.join(dupes)\n",
    "    for tff_id in squad:\n",
    "        if tff_id not in list(player_data['tff_id']):\n",
    "            invalidity_message += f'\\ntff_id {tff_id} not found in player_data.csv'\n",
    "    squad_data = player_data.loc[player_data['tff_id'].isin(squad)]\n",
    "    squad_data = squad_data.sort_values(by='tff_position')\n",
    "    squad_cost = round(squad_data['tff_cost'].sum(),1)\n",
    "    if squad_cost > 50:\n",
    "        invalidity_message += f'\\nSquad is £{round(squad_cost-50,1)}m over budget'\n",
    "    if len(squad_data) > 11:\n",
    "        invalidity_message += f'\\n{len(squad_data)-11} too many players in squad'\n",
    "    squad_info = ''\n",
    "    for key, value in {1:{'pos_label': 'goalkeepers', 'limit': 1},\n",
    "                       2:{'pos_label': 'defenders', 'limit': 5},\n",
    "                       3:{'pos_label': 'midfielders', 'limit': 5},\n",
    "                       4:{'pos_label': 'forwards', 'limit': 3}}.items():\n",
    "        pos_list = [f\"{row['fpl_web_player']} ({row['tff_id']})\" for index, row in squad_data.loc[squad_data['tff_position']==key].iterrows()]\n",
    "        squad_info += '\\n'+', '.join(pos_list)\n",
    "        if len(pos_list) > value['limit']:\n",
    "            invalidity_message += f\"\\n{len(pos_list)-value['limit']} too many {value['pos_label']} in squad\"\n",
    "    squad_info += f'\\n\\nSquad cost: £{squad_cost}m\\n'\n",
    "    print(squad_info)\n",
    "\n",
    "    if invalidity_message != '':\n",
    "        print('\\nInvalid squad' + invalidity_message)\n",
    "    elif save_team_as is not None:\n",
    "        with open('../data/tff_squads.json', 'r') as fp:\n",
    "            data = json.load(fp)\n",
    "        data[save_team_as] = squad\n",
    "        with open('../data/tff_squads.json', 'w') as fp:\n",
    "            json.dump(data, fp)\n",
    "        print(f'Valid squad saved as {save_team_as}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_tff_mp(ev_df, fixture_df, initial_squad, last_date=None, flatten_dates_after=None, \n",
    "                 total_pts_cutoff=None, ppm_cutoff=None,\n",
    "                 ta_tot=40, ta_gw=5, objective='regular', weekly_decay=0.85, transfer_cost=6.5, \n",
    "                 exclusions=None, keeps=None, force_transfer_in=None, force_transfer_out=None, no_transfer_mds=None, show_non_team_ev=False,\n",
    "                 apply_noise=False, seed_val=None, magnitude=1, sim_number=1,\n",
    "                 show_solve_results=True, solver_type='highs', presolve='on', use_cmd=True, time_limit=120):\n",
    "    \n",
    "    if isinstance(initial_squad, str):\n",
    "        \n",
    "        initial_squad = read_squad_from_json(initial_squad)\n",
    "        print('Initial team:')\n",
    "        check_squad_and_save(squad=initial_squad, save_team_as=None)\n",
    "    \n",
    "    if objective == 'regular':\n",
    "        weekly_decay = 1\n",
    "\n",
    "    if show_solve_results:\n",
    "        print(f'{len(ev_df)} players before ev cutoff')\n",
    "    preprocessing_output = preprocess_dfs(ev_df, fixture_df, initial_squad=initial_squad, last_date=last_date, flatten_dates_after=flatten_dates_after, \n",
    "                                          total_pts_cutoff=total_pts_cutoff, ppm_cutoff=ppm_cutoff, weekly_decay=weekly_decay)\n",
    "    ev_df = preprocessing_output['ev_df']\n",
    "    if show_solve_results:\n",
    "        print(f'{len(ev_df)} players after ev cutoff')\n",
    "    fixture_map = preprocessing_output['fixture_map']\n",
    "    \n",
    "    horizon = len(fixture_map)\n",
    "    problem_id = get_random_id(5)\n",
    "    problem_name = f'tff_mp_h{horizon}_regular' if objective == 'regular' else f'tff_mp_h{horizon}_o{objective}_d{weekly_decay}'\n",
    "    \n",
    "    # Sets\n",
    "    players = ev_df.index.tolist()\n",
    "    element_types = type_data.index.tolist()\n",
    "    matchtimes = list(fixture_map.index)\n",
    "    all_matchtimes = [matchtimes[0]-1] + matchtimes\n",
    "    tff_gameweeks = list(fixture_map['tff_gw'].unique())\n",
    "    gw_transfer_allowance = {w: 5 for w in tff_gameweeks}\n",
    "    gw_transfer_allowance[tff_gameweeks[0]] = min(ta_gw,5)\n",
    "\n",
    "    if apply_noise:\n",
    "        rng = np.random.default_rng(seed = seed_val)\n",
    "        ev_df['total_pts'] = 0\n",
    "        player_df = pd.read_csv('../data/player_data.csv')\n",
    "        player_df = player_df[['tff_id', 'noise_factor']]\n",
    "        ev_df = pd.merge(ev_df,player_df,on='tff_id').set_index('tff_id')\n",
    "        if flatten_dates_after is None:\n",
    "            for m in matchtimes:\n",
    "                noise = ev_df[f'{m}_pts'] * 0.15 * rng.standard_normal(size = len(ev_df)) * magnitude\n",
    "                ev_df[f'{m}_pts'] = ev_df[f'{m}_pts'] + round(noise,2)\n",
    "                ev_df[f'{m}_pts'] = np.maximum(ev_df[f'{m}_pts'], 0)\n",
    "                ev_df['total_pts'] += ev_df[f'{m}_pts']\n",
    "        else:\n",
    "            # Noise not applied to column representing multiple match periods\n",
    "            for m in matchtimes[:-1]:\n",
    "                noise = ev_df[f'{m}_pts'] * 0.15 * rng.standard_normal(size = len(ev_df)) * magnitude\n",
    "                ev_df[f'{m}_pts'] = ev_df[f'{m}_pts'] + round(noise,2)\n",
    "                ev_df[f'{m}_pts'] = np.maximum(ev_df[f'{m}_pts'], 0)\n",
    "                ev_df['total_pts'] += ev_df[f'{m}_pts']\n",
    "            ev_df['total_pts'] += ev_df[f'{matchtimes[-1]}_pts']\n",
    "\n",
    "    # Model\n",
    "    model = so.Model(name = problem_name)\n",
    "\n",
    "    # Variables\n",
    "    squad = model.add_variables(players, all_matchtimes, name='squad', vartype=so.binary)\n",
    "    transfer_in = model.add_variables(players, matchtimes, name='transfer_in', vartype=so.binary)\n",
    "    transfer_out = model.add_variables(players, matchtimes, name='transfer_out', vartype=so.binary)\n",
    "    \n",
    "    # Dictionaries\n",
    "    squad_type_count = {(t,m): so.expr_sum(squad[p,m] for p in players if ev_df.loc[p, 'tff_pos'] == type_data.loc[t, 'tff_pos']) for t in element_types for m in matchtimes}\n",
    "    player_value = (ev_df['tff_cost']).to_dict()\n",
    "    squad_value = {m: so.expr_sum(player_value[p] * squad[p,m] for p in players) for m in matchtimes}\n",
    "    points_player_day = {(p,m): ev_df.loc[p, f'{m}_pts'] for p in players for m in matchtimes}\n",
    "    squad_count = {m: so.expr_sum(squad[p, m] for p in players) for m in matchtimes}\n",
    "    \n",
    "    total_number_of_transfers = so.expr_sum(transfer_out[p,m] for p in players for m in matchtimes) \n",
    "\n",
    "    mt_number_of_transfers = {m: so.expr_sum(transfer_out[p,m] for p in players) for m in matchtimes}        \n",
    "    gw_number_of_transfers = {w: so.expr_sum(mt_number_of_transfers[m] for m in matchtimes if int(fixture_map.loc[m, 'tff_gw']) == w) for w in tff_gameweeks}\n",
    "    \n",
    "    # Constraints: squad\n",
    "    if initial_squad is not None:\n",
    "        model.add_constraints((squad[p, 0] == 1 for p in initial_squad), name='initial_squad_players')\n",
    "        model.add_constraints((squad[p, 0] == 0 for p in players if p not in initial_squad), name='initial_squad_others')\n",
    "    else:\n",
    "        initial_squad = []\n",
    "    model.add_constraints((squad_count[m] == 11 for m in matchtimes), name='squad_count')    \n",
    "    # Constraints: formation and budget\n",
    "    model.add_constraints((squad_type_count[t,m] == [type_data.loc[t, 'squad_min_play'], type_data.loc[t, 'squad_max_play']] for t in element_types for m in matchtimes), name='valid_formation_1')\n",
    "    model.add_constraints((squad_value[m] <= 50 for m in matchtimes), name='squad_budget')\n",
    "    # Constraints: transfers\n",
    "    model.add_constraints((squad[p,m] == squad[p,m-1] + transfer_in[p,m] - transfer_out[p,m] for p in players for m in matchtimes), name='squad_transfer_rel')\n",
    "    model.add_constraint(total_number_of_transfers <= min(ta_tot,40), name = 'transfer_allowance')\n",
    "    model.add_constraints((gw_number_of_transfers[w] <= gw_transfer_allowance[w] for w in tff_gameweeks), name = 'gw_transfer_allowance')\n",
    "    if no_transfer_mds is not None:\n",
    "        model.add_constraints((mt_number_of_transfers[m] == 0 for m in no_transfer_mds), name='no_transfer_matchdays')\n",
    "    # Constraints: forced players and transfers\n",
    "    if exclusions is not None:\n",
    "        model.add_constraints((squad[e, m] == 0 for e in exclusions for m in matchtimes), name = 'force_exclude_players')\n",
    "    if keeps is not None:\n",
    "        model.add_constraints((squad[e, m] == 1 for e in keeps for m in matchtimes), name = 'force_keep_players')\n",
    "    if force_transfer_in is not None:\n",
    "        model.add_constraints((squad[force_transfer_in[e][0], force_transfer_in[e][1]] == 1 for e in list(range(len(force_transfer_in)))), name = 'force_transfer_in_players')\n",
    "        model.add_constraints((squad[force_transfer_in[e][0], force_transfer_in[e][1]-1] == 0 for e in list(range(len(force_transfer_in)))), name = 'force_transfer_in_players_2')\n",
    "    if force_transfer_out is not None:\n",
    "        model.add_constraints((squad[force_transfer_out[e][0], force_transfer_out[e][1]] == 0 for e in list(range(len(force_transfer_out)))), name = 'force_transfer_out_players')\n",
    "        model.add_constraints((squad[force_transfer_out[e][0], force_transfer_out[e][1]-1] == 1 for e in list(range(len(force_transfer_out)))), name = 'force_transfer_out_players_2')\n",
    "    \n",
    "    # Objective\n",
    "    md_xp = {m: so.expr_sum(points_player_day[p,m] * (squad[p,m]) for p in players) for m in matchtimes}\n",
    "    if objective == 'regular':\n",
    "        eval_score = so.expr_sum(md_xp[m] + 0.000001*mt_number_of_transfers[m]*m for m in matchtimes) - total_number_of_transfers*transfer_cost\n",
    "        model.set_objective(-eval_score, sense='N', name='total_regular_xp') \n",
    "    else:\n",
    "        eval_score = so.expr_sum(md_xp[m] * fixture_map.loc[m, 'decay'] + 0.000001*mt_number_of_transfers[m]*m for m in matchtimes) - total_number_of_transfers*transfer_cost\n",
    "        model.set_objective(-eval_score, sense='N', name='total_decay_xp')\n",
    "    \n",
    "    # Solve Step\n",
    "    model.export_mps(filename=f'tmp/{problem_name}_{problem_id}_{sim_number}.mps')\n",
    "    if solver_type == 'cbc':\n",
    "        command = f'cbc tmp/{problem_name}_{problem_id}_{sim_number}.mps sec {time_limit} solve solu tmp/{problem_name}_{problem_id}_{sim_number}_sol.txt'\n",
    "        # !{command}\n",
    "        os.system(command)\n",
    "        # Read the solution back to the file\n",
    "        with open(f'tmp/{problem_name}_{problem_id}_{sim_number}_sol.txt', 'r') as f:\n",
    "            for v in model.get_variables():\n",
    "                v.set_value(0)\n",
    "            for line in f:\n",
    "                if 'objective value' in line:\n",
    "                    continue\n",
    "                words = line.split()\n",
    "                var = model.get_variable(words[1])\n",
    "                var.set_value(float(words[2]))\n",
    "    else:\n",
    "        command = f'highs --presolve {presolve} --model_file tmp/{problem_name}_{problem_id}_{sim_number}.mps --time_limit {time_limit} --solution_file tmp/{problem_name}_{problem_id}_{sim_number}_sol.txt'\n",
    "        # use_cmd is set to True to prevent highs from halting mid-process. It can be set to False if this does not happen on your machine\n",
    "        if use_cmd:\n",
    "            def print_output(process):\n",
    "                while True:\n",
    "                    output = process.stdout.readline()\n",
    "                    if 'Solving report' in output:\n",
    "                        time.sleep(2)\n",
    "                        process.kill()\n",
    "                    elif output == '' and process.poll() is not None:\n",
    "                        break\n",
    "                    elif output:\n",
    "                        print(output.strip())\n",
    "\n",
    "            process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "            output_thread = threading.Thread(target=print_output, args=(process,))\n",
    "            output_thread.start()\n",
    "            output_thread.join()\n",
    "        else:\n",
    "            os.system(command)\n",
    "\n",
    "        with open(f'tmp/{problem_name}_{problem_id}_{sim_number}_sol.txt', 'r') as f:\n",
    "            for v in model.get_variables():\n",
    "                v.set_value(0)\n",
    "            cols_started = False\n",
    "            for line in f:\n",
    "                if not cols_started and \"# Columns\" not in line:\n",
    "                    continue\n",
    "                elif \"# Columns\" in line:\n",
    "                    cols_started = True\n",
    "                    continue\n",
    "                elif cols_started and line[0] != \"#\":\n",
    "                    words = line.split()\n",
    "                    v = model.get_variable(words[0])\n",
    "                    try:\n",
    "                        if v.get_type() == so.INT:\n",
    "                            v.set_value(round(float(words[1])))\n",
    "                        elif v.get_type() == so.BIN:\n",
    "                            v.set_value(round(float(words[1])))\n",
    "                        elif v.get_type() == so.CONT:\n",
    "                            v.set_value(round(float(words[1]),3))\n",
    "                    except:\n",
    "                        print(\"Error\", words[0], line)\n",
    "                elif line[0] == \"#\":\n",
    "                    break\n",
    "    \n",
    "    total_xp = round(so.expr_sum(points_player_day[p,m] * (squad[p,m]) for p in players for m in matchtimes).get_value(), 2)\n",
    "    eval_score = round(eval_score.get_value(), 2)\n",
    "    \n",
    "    # Generate a dataframe to display the solution\n",
    "    plan = []\n",
    "    for t in element_types:\n",
    "        for p in players:\n",
    "            if so.expr_sum(squad[p,m] + transfer_out[p,m] for m in matchtimes).get_value() >= 0.5 and ev_df.loc[p, 'tff_pos'] == type_data.loc[t, 'tff_pos']:\n",
    "                lp = ev_df.loc[p]\n",
    "                if p in initial_squad:\n",
    "                    appendment = '*'\n",
    "                else:\n",
    "                    appendment = ''\n",
    "                player_info = [p, lp['team'], lp['tff_pos'], lp['tff_cost'], lp['player']+appendment]\n",
    "                for m in matchtimes:\n",
    "                    current_points = round(points_player_day[p,m], 2)\n",
    "                    if squad[p,m].get_value() > 0.5:\n",
    "                        score = f'{current_points}'\n",
    "                    elif show_non_team_ev and current_points > 0.2:\n",
    "                        score = f'({current_points})'\n",
    "                    else:\n",
    "                        score = ''\n",
    "                    player_info.append(score)\n",
    "                plan.append(player_info)\n",
    "    columns = ['ID','Team', 'Pos','Cost','Name']\n",
    "    for m in matchtimes:\n",
    "        columns.append(f\"{m}\")\n",
    "    plan_df = pd.DataFrame(plan, columns=columns)\n",
    "    plan_df = plan_df.replace(['0.0'],'-')\n",
    "    plan_df = plan_df.replace(['0.0c'],'-')\n",
    "    itb_row = ['','','','','ITB']\n",
    "    for m in matchtimes:\n",
    "        itb = 50 - squad_value[m].get_value()\n",
    "        itb_row.append(itb)\n",
    "    plan_df.loc[len(plan_df)] = itb_row\n",
    "    numeric_header = plan_df.columns.tolist()\n",
    "    time_header = 5*[''] + [parser.parse(row['datetime_str']).strftime(\"%H:%M\") for index, row in fixture_map.iterrows()]\n",
    "    daynum_header = 5*[''] + [ordinal(parser.parse(row['datetime_str']).strftime(\"%d\")) for index, row in fixture_map.iterrows()]\n",
    "    weekday_header = 5*[''] + [parser.parse(row['datetime_str']).strftime(\"%a\") for index, row in fixture_map.iterrows()]\n",
    "    tff_gw_header = 5*[''] + ['GW' + str(row['tff_gw']) for index, row in fixture_map.iterrows()]\n",
    "    month_header = 5*[''] + [parser.parse(row['datetime_str']).strftime(\"%b\") for index, row in fixture_map.iterrows()]\n",
    "    plan_df.columns = [month_header, tff_gw_header, weekday_header, daynum_header, time_header, numeric_header]\n",
    "\n",
    "    # make dataframe to record the players in a simulation\n",
    "    plan = []\n",
    "    if apply_noise:\n",
    "        for t in element_types:\n",
    "            for p in players:\n",
    "                if so.expr_sum(squad[p,m] + transfer_out[p,m] for m in matchtimes).get_value() >= 0.5 and ev_df.loc[p, 'tff_pos'] == type_data.loc[t, 'tff_pos']:\n",
    "                    lp = ev_df.loc[p]\n",
    "                    player_info = [p, lp['team'], lp['tff_pos'], lp['tff_cost'], lp['player']]\n",
    "                    for m in matchtimes:\n",
    "                        if squad[p,m].get_value() > 0.5:\n",
    "                            score = 1\n",
    "                        else:\n",
    "                            score = 0\n",
    "                        player_info.append(score)\n",
    "                    plan.append(player_info)\n",
    "        columns = ['ID','Team', 'Pos','Cost','Name']\n",
    "        for m in matchtimes:\n",
    "            columns.append(f\"{m}\")\n",
    "        players_in_sim = pd.DataFrame(plan, columns=columns)\n",
    "    else:\n",
    "        players_in_sim = None\n",
    "\n",
    "    transfers_made = int(total_number_of_transfers.get_value())\n",
    "\n",
    "    if use_cmd:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    if show_solve_results:\n",
    "        display(plan_df)\n",
    "        print(f'EV: {total_xp}\\tEval score: {eval_score}\\tTransfers made: {transfers_made}')\n",
    "    \n",
    "    return{'model': model, 'total_xp': total_xp, 'eval_score': eval_score, 'plan': plan_df, 'transfers_made': transfers_made, 'players_in_sim': players_in_sim, 'fixture_map': fixture_map}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate many solves with noise\n",
    "def solve_tff_mp_sim(ev_df, fixture_df, initial_squad, last_date=None, flatten_dates_after=None,\n",
    "                       total_pts_cutoff=0.3, ppm_cutoff=0.5,\n",
    "                       ta_tot=50, ta_gw=5, objective='regular', weekly_decay=0.85, transfer_cost=6.5, \n",
    "                       exclusions=None, keeps=None, force_transfer_in=None, force_transfer_out=None, no_transfer_mds=None,show_non_team_ev=False,\n",
    "                       seed_val=None, nsims=5, magnitude=1, display_sim_results=True,\n",
    "                       solver_type='highs', presolve='on', use_cmd=True, time_limit=120):\n",
    "    \n",
    "    if initial_squad is None:\n",
    "        initial_squad = []\n",
    "    transfer_sum = 0\n",
    "    xp_sum = 0\n",
    "    eval_sum = 0\n",
    "\n",
    "    results_dict = {}\n",
    "    for i in range(nsims):\n",
    "        print(f\"Running sim {i+1} of {nsims}...\")\n",
    "        results = solve_tff_mp(ev_df=ev_df, fixture_df=fixture_df, initial_squad=initial_squad, last_date=last_date, flatten_dates_after=flatten_dates_after, \n",
    "                 total_pts_cutoff=total_pts_cutoff, ppm_cutoff=ppm_cutoff,\n",
    "                 ta_tot=ta_tot, ta_gw=ta_gw, objective=objective, weekly_decay=weekly_decay, transfer_cost=transfer_cost, \n",
    "                 exclusions=exclusions, keeps=keeps, force_transfer_in=force_transfer_in, force_transfer_out=force_transfer_out, no_transfer_mds=no_transfer_mds,show_non_team_ev=show_non_team_ev,\n",
    "                 apply_noise=True, seed_val=seed_val, magnitude=magnitude,sim_number=i+1,\n",
    "                 show_solve_results=False, solver_type=solver_type, presolve=presolve, use_cmd=use_cmd, time_limit=time_limit)\n",
    "        results_dict[i] = results['plan']\n",
    "        players_in_sim = results['players_in_sim']\n",
    "        if i == 0:\n",
    "            sensitivity_df = players_in_sim\n",
    "        else:\n",
    "            for index, row in results['players_in_sim'].iterrows():\n",
    "                if row['ID'] in sensitivity_df['ID'].tolist():\n",
    "                    sensitivity_df.loc[sensitivity_df['ID']==row['ID'], '1':] = sensitivity_df.loc[sensitivity_df['ID']==row['ID'], '1':] + row['1':]\n",
    "                    continue\n",
    "                else:\n",
    "                    row_to_append = row.tolist()\n",
    "                    sensitivity_df.loc[len(sensitivity_df)] = row_to_append\n",
    "        clear_output(wait=True)\n",
    "        transfer_sum += results['transfers_made']\n",
    "        xp_sum += results['total_xp']\n",
    "        eval_sum += results['eval_score']\n",
    "    avg_trf = round(transfer_sum/nsims,2)\n",
    "    avg_xp = round(xp_sum/nsims,2)\n",
    "    avg_eval = round(eval_sum/nsims,2)\n",
    "    sensitivity_df.loc[:,'1':] = sensitivity_df.loc[:,'1':] * 100 / nsims\n",
    "    sensitivity_df.loc[:,'1':] = sensitivity_df.loc[:,'1':].astype(int)\n",
    "\n",
    "    # Sort the dataframe by initial team and position\n",
    "    sensitivity_df['max_ocuurences'] = 0\n",
    "    sensitivity_df['init_team'] = 0\n",
    "    sensitivity_df['pos_code'] = 0\n",
    "    for index, row in sensitivity_df.iterrows():\n",
    "        if row['Pos'] == 'G':\n",
    "            sensitivity_df.loc[index,'pos_code'] = 1\n",
    "        elif row['Pos'] == 'D':\n",
    "            sensitivity_df.loc[index,'pos_code'] = 2\n",
    "        elif row['Pos'] == 'M':\n",
    "            sensitivity_df.loc[index,'pos_code'] = 3\n",
    "        else:\n",
    "            sensitivity_df.loc[index,'pos_code'] = 4\n",
    "        if row['ID'] in initial_squad:\n",
    "            sensitivity_df.loc[index,'init_team'] = 1\n",
    "    sensitivity_df = sensitivity_df.sort_values(by=['pos_code', 'init_team'], ascending=[True, False])\n",
    "    sensitivity_df.drop(['max_ocuurences', 'init_team', 'pos_code'], axis=1, inplace=True)\n",
    "    sensitivity_df = sensitivity_df.reset_index(drop=True)\n",
    "    \n",
    "    fixture_map = results['fixture_map']\n",
    "    numeric_header = sensitivity_df.columns.tolist()\n",
    "    time_header = 5*[''] + [parser.parse(row['datetime_str']).strftime(\"%H:%M\") for index, row in fixture_map.iterrows()]\n",
    "    daynum_header = 5*[''] + [ordinal(parser.parse(row['datetime_str']).strftime(\"%d\")) for index, row in fixture_map.iterrows()]\n",
    "    weekday_header = 5*[''] + [parser.parse(row['datetime_str']).strftime(\"%a\") for index, row in fixture_map.iterrows()]\n",
    "    tff_gw_header = 5*[''] + ['GW' + str(row['tff_gw']) for index, row in fixture_map.iterrows()]\n",
    "    month_header = 5*[''] + [parser.parse(row['datetime_str']).strftime(\"%b\") for index, row in fixture_map.iterrows()]\n",
    "    sensitivity_df.columns = [month_header, tff_gw_header, weekday_header, daynum_header, time_header, numeric_header]\n",
    "    sens = sensitivity_df.copy()\n",
    "    sens = sens.style.background_gradient(cmap=\"RdPu\", subset=sensitivity_df.columns[5:]).format(precision=1)\n",
    "    sens = sens.set_table_styles([\n",
    "                        {'selector': 'th.col_heading', 'props': 'text-align: left;'},\n",
    "                        {'selector': 'th.col_heading.level0', 'props': 'font-size: 1em;'},\n",
    "                        {'selector': 'td', 'props': 'text-align: center; font-weight: bold;'},\n",
    "                    ], overwrite=False)\n",
    "    \n",
    "    if display_sim_results:\n",
    "        display(sens)\n",
    "        print(f\"Number of sims: {nsims}\\tTransfer cost: {transfer_cost}\\tNoise magnitude: {magnitude}\\nAvg transfers made: {avg_trf}\\t  EV: {avg_xp}\\tEval: {avg_eval}\")\n",
    "                \n",
    "    return {'sensitivity_df': sens, 'avg_trf': avg_trf, 'avg_xp': avg_xp, 'avg_eval': avg_eval, 'sensitivity_df_unformatted': sensitivity_df, 'results_dict': results_dict}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_df = pd.DataFrame(columns=('comp', 'home_team', 'away_team', 'datetime_probs'))\n",
    "cf_df.loc[len(cf_df)] = ['pl', 'CRY', 'LIV', {'2024-10-05T12:30:00Z':1}]\n",
    "cf_df.loc[len(cf_df)] = ['pl', 'EVE', 'NEW', {'2024-10-05T19:30:00Z':1}]\n",
    "cf_df.loc[len(cf_df)] = ['pl', 'AVL', 'MUN', {'2024-10-06T14:00:00Z':1}]\n",
    "cf_df.loc[len(cf_df)] = ['pl', 'BHA', 'TOT', {'2024-10-06T16:30:00Z':1}]\n",
    "\n",
    "cf_df.loc[len(cf_df)] = ['pl', 'TOT', 'WHU', {'2024-10-19T12:30:00Z':1}]\n",
    "cf_df.loc[len(cf_df)] = ['pl', 'LIV', 'CHE', {'2024-10-19T19:30:00Z':1}]\n",
    "cf_df.loc[len(cf_df)] = ['pl', 'BOU', 'ARS', {'2024-10-20T14:00:00Z':1}]\n",
    "cf_df.loc[len(cf_df)] = ['pl', 'WOL', 'MCI', {'2024-10-20T16:30:00Z':1}]\n",
    "\n",
    "cf_df.loc[len(cf_df)] = ['pl', 'LEI', 'FOR', {'2024-10-25T20:00:00Z':1}]\n",
    "cf_df.loc[len(cf_df)] = ['pl', 'EVE', 'FUL', {'2024-10-26T19:30:00Z':1}]\n",
    "cf_df.loc[len(cf_df)] = ['pl', 'CHE', 'NEW', {'2024-10-27T14:00:00Z':1}]\n",
    "cf_df.loc[len(cf_df)] = ['pl', 'CRY', 'TOT', {'2024-10-27T14:00:00Z':1}]\n",
    "cf_df.loc[len(cf_df)] = ['pl', 'WHU', 'MUN', {'2024-10-27T14:00:00Z':1}]\n",
    "cf_df.loc[len(cf_df)] = ['pl', 'ARS', 'LIV', {'2024-10-27T16:30:00Z':1}]\n",
    "\n",
    "fixture_results = generate_fixtures(custom_fixtures=None, exclude_past_games=True, last_date=None, display_unformatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_results = generate_ev(custom_fixtures=None, exclude_past_games=True, last_date='2025-01-15', xmin_cutoff=30)\n",
    "ev_df = ev_results['ev_df']\n",
    "fixture_df = ev_results['fixture_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_squad_and_save(squad=[], save_team_as='example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solve_results = solve_tff_mp(ev_df=ev_df, fixture_df=fixture_df, initial_squad=None, last_date='2025-01-15', flatten_dates_after='2024-10-5',\n",
    "                             total_pts_cutoff=0.3, ppm_cutoff=0.5,\n",
    "                             ta_tot=40, ta_gw=5, objective='decay', weekly_decay=0.95, transfer_cost=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_results = solve_tff_mp_sim(ev_df=ev_df, fixture_df=fixture_df, initial_squad=None, last_date='2025-01-15', flatten_dates_after='2024-10-5',\n",
    "                               total_pts_cutoff=0.3, ppm_cutoff=0.5,\n",
    "                               ta_tot=40, ta_gw=5, objective='decay', weekly_decay=0.95, transfer_cost=7,\n",
    "                               seed_val=None, nsims=20, magnitude=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_results['results_dict'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "ev_df_1 = ev_df.copy()\n",
    "ev_df_1 = ev_df_1.loc[ev_df_1['total_pts']>0]\n",
    "\n",
    "## Uncomment lines to focus on specific positions\n",
    "# ev_df_1 = ev_df_1.loc[ev_df_1['tff_pos']!='G']\n",
    "# ev_df_1 = ev_df_1.loc[ev_df_1['tff_pos']!='D']\n",
    "# ev_df_1 = ev_df_1.loc[ev_df_1['tff_pos']!='M']\n",
    "# ev_df_1 = ev_df_1.loc[ev_df_1['tff_pos']!='F']\n",
    "\n",
    "ax = sns.scatterplot(x=ev_df_1['tff_cost'], y=ev_df_1['total_pts'], hue=ev_df_1['tff_pos'])\n",
    "sns.move_legend(ax, 'upper left')\n",
    "for index, row in ev_df_1.iterrows():\n",
    "     ax.text(row['tff_cost']+.02, row['total_pts'], str(row['player']))\n",
    "\n",
    "# ax.set_xlim(2, 9)\n",
    "# ax.set_ylim(0, 140)\n",
    "# Add a value line by setting parameters and uncommenting the following lines\n",
    "# X_plot = np.linspace(2, 9, 100)\n",
    "# Y_plot = 12.5*X_plot+20\n",
    "# ax.plot(X_plot, Y_plot, color='r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
